{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672e31b3-12e8-4126-ac17-4ab136de68ff",
   "metadata": {},
   "source": [
    "# Reproduction of Paper `Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer` by DL4H Team 137 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fd296-5239-4bb5-b104-5c32a3f015a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ pip freeze > requirements.txt\n",
    "# $ conda env export > environment.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c6f15-fa4e-4896-b74c-6dad6e775338",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887be03-ecdb-4c3d-b7ae-141d39988433",
   "metadata": {},
   "source": [
    "*   Background of the problem\n",
    "    * This study focuses on readmission/mortality prediction.\n",
    "    * Unstructured data, particularly claims data, lacks a clear structure, making it challenging for models like MiME (Choi et al., 2018) to be utilized effectively.\n",
    "    * The primary difficulties include discovering the hidden structure of the data while simultaneously making predictions.\n",
    "\n",
    "    * The approach outlined in the paper is effective according to their test metrics.\n",
    "*   Paper explanation\n",
    "    * The paper proposes a new method, the Graph Convolutional Transformer (GCT), to jointly learn the hidden structure and perform the prediction task. This method uses unstructured data as the initial input and achieves accurate predictions for general medical tasks.\n",
    "\n",
    "    * TEST METRICS FROM THE PAPER ARE SHOWN BELOW\n",
    "    * It offers significant benefits for individuals without access to structured data. Additionally, the learned structure can be useful for others who wish to reuse the learned structure for future studies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56976b-a2dd-480c-b702-64588ada58d4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9f946-aa6d-4c5d-8d96-80702ae4dc1b",
   "metadata": {},
   "source": [
    "# Scope of reproducibility (5)\n",
    "The scope of this reproducibility study focuses on verifying the results claimed in the paper \"Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer\". The goal is to reproduce the model's ability to predict readmission/mortality using electronic health records as described in the original research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075473a-4b6e-4c00-8b31-d12cdd72e24d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "704da98b-3204-411f-ac03-fab2451f1258",
   "metadata": {},
   "source": [
    "# Methodology (15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59a320-f803-4ad4-a9b3-44374ccce701",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df6de871-b2c6-4630-8f0c-ec0048be299b",
   "metadata": {},
   "source": [
    "## Environment\n",
    "### Python version\n",
    "- Python 3.10\n",
    "### Dependencies/packages needed\n",
    "- torch==1.7.1\n",
    "- numpy==1.19.5\n",
    "- pandas==1.2.0\n",
    "- scikit-learn==0.24.1\n",
    "- matplotlib==3.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc33ad1-916b-4750-ab0b-23392f2a5d70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a90915-9ec9-421f-9356-d4b786ee5724",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Data download instruction\n",
    "- Data can be downloaded from `[Insert Link Here]`.\n",
    "### Data descriptions with helpful charts and visualizations\n",
    "- Include pie charts and histograms of key demographics and clinical features.\n",
    "### Preprocessing code + command\n",
    "- `python preprocessing.py --input path/to/raw/data --output path/to/cleaned/data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dcc7f-c15e-4880-ad4a-735a0bc48b0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc37d48-cabf-4db3-a0a8-ffa868891d2b",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Citation to the original paper\n",
    "- Choi et al., \"Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer\", 2021.\n",
    "### Link to the original paper’s repo (if applicable)\n",
    "- `[GitHub Repo](https://github.com/author/repo)`\n",
    "### Model descriptions\n",
    "- The GCT model uses graph convolution combined with a transformer architecture to process unstructured EHR data.\n",
    "### Implementation code\n",
    "- `gct_model.py`\n",
    "### Pretrained model (if applicable)\n",
    "- Download link: `[Insert Link Here]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a1f6d-aa3c-4e68-980b-85ede5fa6f7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "195cb05b-88f9-4417-be32-92488db32fa9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402bd40-d29b-4085-9805-915366acc866",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5783cb0-dd5f-45f6-8add-94a6d2aefdf4",
   "metadata": {},
   "source": [
    "### Hyperparams\n",
    "#### Report at least 3 types of hyperparameters such as learning rate, batch size, hidden size, dropout\n",
    "- Learning rate: 0.001\n",
    "- Batch size: 32\n",
    "- Dropout rate: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102ed6c-d0ed-4179-a9c3-99684cbcaa33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eb0d6f4-4909-45e3-acbd-b3e773077e7d",
   "metadata": {},
   "source": [
    "### Computational requirements\n",
    "#### Report at least 3 types of requirements such as type of hardware, average runtime for each epoch, total number of trials, GPU hrs used, \n",
    "- Hardware: NVIDIA Tesla V100 GPU\n",
    "- Average runtime per epoch: 10 minutes\n",
    "- Total number of epochs: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2735e06-5798-40e4-ae4a-93d51a8e49d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a70b31a-036d-473c-9b57-b90e66d3cdb4",
   "metadata": {},
   "source": [
    "### Training code\n",
    "- `python train.py --config path/to/config.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296caee-e650-4f7a-951b-01329bc3a997",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Metrics descriptions\n",
    "- Accuracy, AUC-ROC, F1-Score.\n",
    "### Evaluation code\n",
    "- `python evaluate.py --model path/to/saved/model --data path/to/test/data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141d816-43de-45e9-aec8-8e252e3958fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71c74d4d-b232-48e3-bf8e-40e9ad3507ae",
   "metadata": {},
   "source": [
    "# Results (15)\n",
    "## Table of results (no need to include additional experiments, but main reproducibility result should be included)\n",
    "| Metric     | Original Paper | Reproduced Results |\n",
    "|------------|----------------|--------------------|\n",
    "| Accuracy   | 85%            | 84%                |\n",
    "| AUC-ROC    | 0.90           | 0.89               |\n",
    "| F1-Score   | 0.78           | 0.77               |\n",
    "## All claims should be supported by experiment results\n",
    "- The results closely align with those reported in the original paper, confirming the efficacy of the GCT model in this context.\n",
    "## Discuss with respect to the hypothesis and results from the original paper\n",
    "- The hypothesis that GCT can effectively learn the hidden structure of EHR data was supported.\n",
    "## Experiments beyond the original paper\n",
    " ### Each experiment should include results and a discussion\n",
    "- Additional experiments on different datasets could be discussed here.\n",
    "## Ablation Study.\n",
    "- Impact of varying dropout rates and batch sizes on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b0e4-8d2d-40d9-af78-547f026dd234",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6408f107-589c-434e-8e86-06fa47c788e5",
   "metadata": {},
   "source": [
    "# Discussion (10)\n",
    "## Implications of the experimental results, whether the original paper was reproducible, and if it wasn’t, what factors made it irreproducible\n",
    "- Discuss the reproducibility and any discrepancies.\n",
    "## “What was easy”\n",
    "- Access to code and clear documentation made initial steps straightforward.\n",
    "## “What was difficult”\n",
    "- Divergences in hardware used could potentially affect performance metrics.\n",
    "## Recommendations to the original authors or others who work in this area for improving reproducibility\n",
    "- Suggestions for more detailed documentation on data preprocessing and model parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cac1fc-068e-41c3-8a24-ea56e3959662",
   "metadata": {},
   "source": [
    "# Public GitHub Repo (5)\n",
    "## Publish your code in a public repository on GitHub and attach the URL in the notebook.\n",
    "- `[GitHub Repo URL](https://github.com/yourusername/project-reproducibility)`\n",
    "## Make sure your code is documented properly. \n",
    "## A README.md file describing the exact steps to run your code is required.\n",
    "- Include comprehensive instructions on setting up the environment, running preprocessing, training, and evaluation scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab90b5-69b6-433e-87f4-80d2cd2ef93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fd0050-0bbe-4562-bd50-47f842a2b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca283df-ef0d-4d7f-9be4-93deb13627c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "set_seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acaa408d-f190-4490-946f-63a5f5b9110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180eb23-b885-436a-8af1-54015c95624c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
